{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPoJxW/FOtWfEIi6oqlnfc5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3d28c3944d9a4684a776ecd94698fe9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_484f45e8ffdc47e6a7a403f09ea6f290",
              "IPY_MODEL_a8a78670eb534735aeeffc2aaaf33912",
              "IPY_MODEL_8d9281e558c1435791c17fc63f1ea0dd"
            ],
            "layout": "IPY_MODEL_1d391fcb170f4335882c324591eb5c66"
          }
        },
        "484f45e8ffdc47e6a7a403f09ea6f290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_610120528f2a4a628631ed4d357e2537",
            "placeholder": "​",
            "style": "IPY_MODEL_9c11c46b6944417ca1bcbafbc68dad5d",
            "value": "100%"
          }
        },
        "a8a78670eb534735aeeffc2aaaf33912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6cf092fba74487d968002259d7a52bb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f132383a3258474fbaa4505361ed96e6",
            "value": 1
          }
        },
        "8d9281e558c1435791c17fc63f1ea0dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8518b48215ca4789a22615bc5d4c3d0f",
            "placeholder": "​",
            "style": "IPY_MODEL_4fb9862371ac4c729849642d52ceb578",
            "value": " 1/1 [00:44&lt;00:00, 44.74s/it]"
          }
        },
        "1d391fcb170f4335882c324591eb5c66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "610120528f2a4a628631ed4d357e2537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c11c46b6944417ca1bcbafbc68dad5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6cf092fba74487d968002259d7a52bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f132383a3258474fbaa4505361ed96e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8518b48215ca4789a22615bc5d4c3d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4fb9862371ac4c729849642d52ceb578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hamzah1507/Medical-Diagnosis-AI/blob/main/Medical_Diagnosis_AI_Assistant.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "# Note: sqlite3 is a built-in library, so we remove it from the pip install list.\n",
        "# PyTorch is needed for TabNet, which requires a specific installation for the Colab environment/GPU\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install pytorch-tabnet shap lime streamlit scikit-learn xgboost pandas numpy\n",
        "\n",
        "# Import core libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sqlite3 # Built-in, no install needed\n",
        "import streamlit as st\n",
        "import torch # Explicitly import torch\n",
        "\n",
        "# ML/DL Libraries\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from xgboost import XGBClassifier\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "\n",
        "# Explainability\n",
        "import shap\n",
        "import lime\n",
        "from lime import lime_tabular\n",
        "\n",
        "# Utilities\n",
        "import os\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"All required libraries installed and imported successfully!\")\n",
        "\n",
        "# Check PyTorch installation\n",
        "print(f\"PyTorch version: {torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcJI2Co2s8pP",
        "outputId": "766a3588-a6fc-4a85-b4ce-fc7970d3b691"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.12/dist-packages (4.1.0)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.48.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.12/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.12/dist-packages (1.50.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.0.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (1.16.2)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.12/dist-packages (from pytorch-tabnet) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.12/dist-packages (from shap) (4.15.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from lime) (3.10.0)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.12/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<6,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.0)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.27.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2.7.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.10.5)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (2025.10.4)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.20.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.13.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.3->pytorch-tabnet) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->lime) (3.2.5)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<6,>=4.0->streamlit) (0.27.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "All required libraries installed and imported successfully!\n",
            "PyTorch version: 2.8.0+cu126\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SIMULATE THE DATASET ---\n",
        "\n",
        "# Define a list of 41 synthetic disease names\n",
        "# We'll generate 40 names plus one 'Healthy' or 'No Disease' category\n",
        "# --- SIMULATE THE DATASET (MODIFIED FOR REAL NAMES) ---\n",
        "\n",
        "# Define a list of 41 synthetic disease names (40 real-world examples + No Disease)\n",
        "disease_names = [\n",
        "    'Influenza', 'Common_Cold', 'COVID-19', 'Strep_Throat', 'Pneumonia',\n",
        "    'Bronchitis', 'Allergies', 'Migraine', 'Tension_Headache', 'Sinusitis',\n",
        "    'Gastroenteritis', 'IBS', 'Appendicitis', 'UTI', 'Kidney_Stones',\n",
        "    'Arthritis', 'Gout', 'Lupus', 'Dengue_Fever', 'Malaria',\n",
        "    'Tuberculosis', 'Hepatitis_A', 'Hepatitis_B', 'HIV', 'Anemia',\n",
        "    'Diabetes', 'Hypertension', 'Hypothyroidism', 'Hyperthyroidism', 'Asthma',\n",
        "    'Eczema', 'Psoriasis', 'Acne', 'Anxiety_Disorder', 'Depression',\n",
        "    'Bipolar_Disorder', 'Schizophrenia', 'Insomnia', 'Sleep_Apnea', 'Obesity',\n",
        "    'No_Disease' # 41st category\n",
        "]\n",
        "N_DISEASES = len(disease_names) # 41\n",
        "# Define a set of 50 common synthetic symptoms/features\n",
        "N_FEATURES = 50\n",
        "feature_names = [f'Symptom_{i+1}' for i in range(N_FEATURES)]\n",
        "\n",
        "# Number of patient records\n",
        "N_SAMPLES = 10000\n",
        "\n",
        "# Generate synthetic data\n",
        "# Features will be binary (0/1) indicating presence or absence of a symptom\n",
        "np.random.seed(42) # for reproducibility\n",
        "\n",
        "# Create the features (X)\n",
        "# Generate random integers (0 or 1) for symptoms\n",
        "X_data = np.random.randint(0, 2, size=(N_SAMPLES, N_FEATURES))\n",
        "X_df = pd.DataFrame(X_data, columns=feature_names)\n",
        "\n",
        "# Create the target (y)\n",
        "# Randomly assign one of the 41 diseases\n",
        "y_data = np.random.choice(disease_names, size=N_SAMPLES)\n",
        "y_df = pd.DataFrame(y_data, columns=['Target_Disease'])\n",
        "\n",
        "# Combine features and target\n",
        "df = pd.concat([X_df, y_df], axis=1)\n",
        "\n",
        "# Save the synthetic dataset to a CSV file (to simulate a real-world file load)\n",
        "DATA_FILE = 'medical_diagnosis_data.csv'\n",
        "df.to_csv(DATA_FILE, index=False)\n",
        "\n",
        "# --- LOAD THE DATASET ---\n",
        "\n",
        "# Load the data back from the generated CSV\n",
        "data = pd.read_csv(DATA_FILE)\n",
        "\n",
        "# Display the first few rows and summary\n",
        "print(f\"Data successfully created and loaded: '{DATA_FILE}'\")\n",
        "print(f\"Shape of the dataset: {data.shape}\")\n",
        "print(\"\\nFirst 5 rows of the dataset:\")\n",
        "print(data.head())\n",
        "print(\"\\nDistribution of the target disease (Top 5):\")\n",
        "print(data['Target_Disease'].value_counts().head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQviWBvQtGi9",
        "outputId": "b8555307-ce34-4905-8dc0-92cc7202a094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data successfully created and loaded: 'medical_diagnosis_data.csv'\n",
            "Shape of the dataset: (10000, 51)\n",
            "\n",
            "First 5 rows of the dataset:\n",
            "   Symptom_1  Symptom_2  Symptom_3  Symptom_4  Symptom_5  Symptom_6  \\\n",
            "0          0          1          0          0          0          1   \n",
            "1          0          1          0          1          0          1   \n",
            "2          0          1          1          1          1          1   \n",
            "3          0          0          0          0          0          1   \n",
            "4          0          1          0          0          1          0   \n",
            "\n",
            "   Symptom_7  Symptom_8  Symptom_9  Symptom_10  ...  Symptom_42  Symptom_43  \\\n",
            "0          0          0          0           1  ...           0           1   \n",
            "1          1          0          0           0  ...           1           1   \n",
            "2          1          1          1           0  ...           0           1   \n",
            "3          0          1          0           1  ...           0           0   \n",
            "4          1          1          1           0  ...           0           1   \n",
            "\n",
            "   Symptom_44  Symptom_45  Symptom_46  Symptom_47  Symptom_48  Symptom_49  \\\n",
            "0           1           1           1           1           0           1   \n",
            "1           1           1           1           1           1           1   \n",
            "2           1           1           0           0           0           0   \n",
            "3           0           0           1           1           1           0   \n",
            "4           0           0           1           0           0           0   \n",
            "\n",
            "   Symptom_50  Target_Disease  \n",
            "0           1      Bronchitis  \n",
            "1           0             IBS  \n",
            "2           1    Appendicitis  \n",
            "3           0   Kidney_Stones  \n",
            "4           0  Hypothyroidism  \n",
            "\n",
            "[5 rows x 51 columns]\n",
            "\n",
            "Distribution of the target disease (Top 5):\n",
            "Target_Disease\n",
            "Bronchitis       279\n",
            "Migraine         277\n",
            "COVID-19         276\n",
            "Kidney_Stones    270\n",
            "Pneumonia        260\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Separate Features (X) and Target (y) ---\n",
        "\n",
        "# The last column is 'Target_Disease'\n",
        "X = data.iloc[:, :-1]\n",
        "y = data['Target_Disease']\n",
        "\n",
        "# Convert all feature names (Symptom_1, etc.) to strings,\n",
        "# as TabNet expects them for feature selection and indexing.\n",
        "X.columns = X.columns.astype(str)\n",
        "\n",
        "print(f\"Features (X) shape: {X.shape}\")\n",
        "print(f\"Target (y) shape: {y.shape}\")\n",
        "\n",
        "# --- 2. Encode the Target Variable ---\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "le = LabelEncoder()\n",
        "\n",
        "# Fit and transform the categorical disease names into numerical labels (0 to 40)\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "# Store the encoder for later use (to map predictions back to disease names)\n",
        "ENCODER_FILE = 'label_encoder.pkl'\n",
        "with open(ENCODER_FILE, 'wb') as f:\n",
        "    pickle.dump(le, f)\n",
        "\n",
        "print(f\"Target encoded. Total classes: {len(le.classes_)}\")\n",
        "print(f\"Label Encoder saved to: {ENCODER_FILE}\")\n",
        "\n",
        "# --- 3. Split the Data ---\n",
        "\n",
        "# Split the data into training (80%) and testing (20%) sets\n",
        "# Use the encoded target y_encoded\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
        ")\n",
        "\n",
        "# Convert all data splits to NumPy arrays as required by TabNet\n",
        "X_train = X_train.values.astype(np.float32)\n",
        "X_test = X_test.values.astype(np.float32)\n",
        "y_train = y_train.astype(np.int64)\n",
        "y_test = y_test.astype(np.int64)\n",
        "\n",
        "print(\"\\nData Splitting Complete:\")\n",
        "print(f\"X_train shape: {X_train.shape} | y_train shape: {y_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape} | y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "942SA0mstOnE",
        "outputId": "d594b63a-c0d7-4bb5-d375-23425f1d4eac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features (X) shape: (10000, 50)\n",
            "Target (y) shape: (10000,)\n",
            "Target encoded. Total classes: 41\n",
            "Label Encoder saved to: label_encoder.pkl\n",
            "\n",
            "Data Splitting Complete:\n",
            "X_train shape: (8000, 50) | y_train shape: (8000,)\n",
            "X_test shape: (2000, 50) | y_test shape: (2000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary components for this cell\n",
        "import torch\n",
        "import pickle\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from xgboost import XGBClassifier\n",
        "import numpy as np\n",
        "# Assuming X_train, y_train, X_test, y_test, le are still defined from Step 3\n",
        "\n",
        "# --- 1. Train TabNet Classifier (Revised Save Path) ---\n",
        "\n",
        "print(\"Starting TabNet training...\")\n",
        "tabnet_model = TabNetClassifier(\n",
        "    n_a=8, n_d=8,\n",
        "    optimizer_fn=torch.optim.Adam,\n",
        "    optimizer_params=dict(lr=2e-2),\n",
        "    scheduler_params={\"step_size\":50, \"gamma\":0.9},\n",
        "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
        "    mask_type='sparsemax',\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "tabnet_model.fit(\n",
        "    X_train=X_train, y_train=y_train,\n",
        "    eval_set=[(X_test, y_test)],\n",
        "    eval_name=['test'],\n",
        "    max_epochs=20,\n",
        "    patience=5,\n",
        "    batch_size=1024,\n",
        "    virtual_batch_size=128,\n",
        "    num_workers=0,\n",
        "    weights=0,\n",
        ")\n",
        "\n",
        "# Save the TabNet model weights with an explicit .zip extension for clarity\n",
        "TABNET_MODEL_FILE = 'tabnet_model.zip'\n",
        "# When saving with an explicit zip name, it often saves to the root directory without a folder\n",
        "tabnet_model.save_model(TABNET_MODEL_FILE.replace('.zip', '')) # save_model only takes the name\n",
        "print(f\"TabNet Model saved as file: {TABNET_MODEL_FILE}\")\n",
        "\n",
        "# --- 2. Train XGBoost Classifier (Same as before) ---\n",
        "\n",
        "print(\"\\nStarting XGBoost training...\")\n",
        "xgb_model = XGBClassifier(\n",
        "    objective='multi:softmax',\n",
        "    num_class=len(le.classes_),\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='merror',\n",
        "    n_estimators=100,\n",
        "    random_state=42,\n",
        "    tree_method='hist'\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Save the XGBoost model\n",
        "XGB_MODEL_FILE = 'xgb_model.pkl'\n",
        "with open(XGB_MODEL_FILE, 'wb') as f:\n",
        "    pickle.dump(xgb_model, f)\n",
        "\n",
        "print(f\"XGBoost Model saved to: {XGB_MODEL_FILE}\")\n",
        "print(\"\\nModel training complete. Now ready for Step 5.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfjRYZxFtjJy",
        "outputId": "87129ff4-6d1b-4385-f051-0a046f62c1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting TabNet training...\n",
            "epoch 0  | loss: 4.23227 | test_accuracy: 0.0235  |  0:00:01s\n",
            "epoch 1  | loss: 3.75726 | test_accuracy: 0.0225  |  0:00:02s\n",
            "epoch 2  | loss: 3.71584 | test_accuracy: 0.025   |  0:00:03s\n",
            "epoch 3  | loss: 3.71309 | test_accuracy: 0.026   |  0:00:04s\n",
            "epoch 4  | loss: 3.71248 | test_accuracy: 0.024   |  0:00:05s\n",
            "epoch 5  | loss: 3.71132 | test_accuracy: 0.025   |  0:00:05s\n",
            "epoch 6  | loss: 3.70971 | test_accuracy: 0.024   |  0:00:06s\n",
            "epoch 7  | loss: 3.70894 | test_accuracy: 0.0235  |  0:00:06s\n",
            "epoch 8  | loss: 3.70782 | test_accuracy: 0.024   |  0:00:07s\n",
            "\n",
            "Early stopping occurred at epoch 8 with best_epoch = 3 and best_test_accuracy = 0.026\n",
            "Successfully saved model at tabnet_model.zip\n",
            "TabNet Model saved as file: tabnet_model.zip\n",
            "\n",
            "Starting XGBoost training...\n",
            "XGBoost Model saved to: xgb_model.pkl\n",
            "\n",
            "Model training complete. Now ready for Step 5.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary components for this cell\n",
        "import numpy as np\n",
        "import pickle\n",
        "import torch\n",
        "from pytorch_tabnet.tab_model import TabNetClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# --- 1. Load Models and Encoder ---\n",
        "\n",
        "# Re-initialize TabNet model structure\n",
        "tabnet_model_loaded = TabNetClassifier(n_a=8, n_d=8)\n",
        "TABNET_MODEL_FILE = 'tabnet_model.zip'\n",
        "\n",
        "# Load the weights from the file saved in the revised Step 4\n",
        "# We use the file name without the .zip extension in the load_model function\n",
        "TABNET_MODEL_LOAD_NAME = TABNET_MODEL_FILE.replace('.zip', '')\n",
        "print(f\"Attempting to load TabNet model from: {TABNET_MODEL_FILE}\")\n",
        "try:\n",
        "    tabnet_model_loaded.load_model(TABNET_MODEL_LOAD_NAME)\n",
        "except Exception as e:\n",
        "    print(f\"TabNet loading error: {e}\")\n",
        "    # Fallback to the explicit .zip path if the name without extension fails\n",
        "    tabnet_model_loaded.load_model(f'{TABNET_MODEL_LOAD_NAME}.zip')\n",
        "\n",
        "# Load XGBoost model\n",
        "XGB_MODEL_FILE = 'xgb_model.pkl'\n",
        "print(f\"Loading XGBoost model from: {XGB_MODEL_FILE}\")\n",
        "with open(XGB_MODEL_FILE, 'rb') as f:\n",
        "    xgb_model_loaded = pickle.load(f)\n",
        "\n",
        "# Load Label Encoder\n",
        "ENCODER_FILE = 'label_encoder.pkl'\n",
        "print(f\"Loading Label Encoder from: {ENCODER_FILE}\")\n",
        "with open(ENCODER_FILE, 'rb') as f:\n",
        "    le_loaded = pickle.load(f)\n",
        "\n",
        "# Assuming X_test, y_test are available from the environment\n",
        "\n",
        "print(\"\\nModels and Label Encoder loaded successfully.\")\n",
        "\n",
        "# --- 2. Define Ensemble Prediction Function ---\n",
        "\n",
        "def ensemble_predict_proba(X):\n",
        "    \"\"\"Generates combined prediction probabilities using soft voting.\"\"\"\n",
        "    tabnet_proba = tabnet_model_loaded.predict_proba(X.astype(np.float32))\n",
        "    xgb_proba = xgb_model_loaded.predict_proba(X)\n",
        "    ensemble_proba = (tabnet_proba + xgb_proba) / 2\n",
        "    return ensemble_proba\n",
        "\n",
        "def ensemble_predict(X):\n",
        "    \"\"\"Generates the final class prediction based on ensemble probability.\"\"\"\n",
        "    ensemble_proba = ensemble_predict_proba(X)\n",
        "    predictions = np.argmax(ensemble_proba, axis=1)\n",
        "    return predictions\n",
        "\n",
        "\n",
        "# --- 3. Evaluate Ensemble Model ---\n",
        "\n",
        "print(\"\\nEvaluating Ensemble Model on Test Set...\")\n",
        "y_pred_ensemble = ensemble_predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred_ensemble)\n",
        "print(f\"TabNet + XGBoost Ensemble Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# --- 4. Get Example Prediction (for verification) ---\n",
        "\n",
        "example_predictions = le_loaded.inverse_transform(y_pred_ensemble[:5])\n",
        "example_true_labels = le_loaded.inverse_transform(y_test[:5])\n",
        "\n",
        "print(\"\\nExample Ensemble Predictions (True vs. Predicted):\")\n",
        "print(f\"True Labels:   {example_true_labels}\")\n",
        "print(f\"Predictions: {example_predictions}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6i9EDJutpZh",
        "outputId": "a260bb62-3f27-4585-e421-3b1fa84ed7cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to load TabNet model from: tabnet_model.zip\n",
            "TabNet loading error: [Errno 2] No such file or directory: 'tabnet_model'\n",
            "Loading XGBoost model from: xgb_model.pkl\n",
            "Loading Label Encoder from: label_encoder.pkl\n",
            "\n",
            "Models and Label Encoder loaded successfully.\n",
            "\n",
            "Evaluating Ensemble Model on Test Set...\n",
            "TabNet + XGBoost Ensemble Accuracy: 0.0270\n",
            "\n",
            "Example Ensemble Predictions (True vs. Predicted):\n",
            "True Labels:   ['Migraine' 'Obesity' 'COVID-19' 'HIV' 'Dengue_Fever']\n",
            "Predictions: ['Common_Cold' 'Hypothyroidism' 'Pneumonia' 'Sleep_Apnea' 'Depression']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-import necessary components for this cell\n",
        "import numpy as np\n",
        "import shap\n",
        "import lime\n",
        "from lime import lime_tabular\n",
        "import pandas as pd\n",
        "import torch\n",
        "\n",
        "# Assuming X_test, y_test, ensemble_predict, ensemble_predict_proba, le_loaded, X_train, and data are available\n",
        "\n",
        "# --- SHAP Prediction Wrapper (Necessary to ensure 2D output) ---\n",
        "def shap_predict_proba(X):\n",
        "    \"\"\"\n",
        "    Wrapper for ensemble_predict_proba to ensure SHAP Explainer gets the 2D output it needs.\n",
        "    \"\"\"\n",
        "    if X.ndim == 1:\n",
        "        X = X.reshape(1, -1)\n",
        "\n",
        "    proba = ensemble_predict_proba(X)\n",
        "    return proba.reshape(X.shape[0], -1)\n",
        "\n",
        "\n",
        "# Get a single patient's data for local explanation\n",
        "EXPLAIN_INDEX = 100\n",
        "X_sample = X_test[EXPLAIN_INDEX:EXPLAIN_INDEX+1]\n",
        "y_sample_true_index = y_test[EXPLAIN_INDEX]\n",
        "y_sample_true_label = le_loaded.inverse_transform([y_sample_true_index])[0]\n",
        "y_sample_pred_index = ensemble_predict(X_sample)[0]\n",
        "y_sample_pred_label = le_loaded.inverse_transform([y_sample_pred_index])[0]\n",
        "y_sample_pred_proba = ensemble_predict_proba(X_sample)[0]\n",
        "\n",
        "print(f\"--- Explaining Patient Index {EXPLAIN_INDEX} ---\")\n",
        "print(f\"True Label: {y_sample_true_label} | Predicted Label: {y_sample_pred_label}\")\n",
        "print(f\"Predicted Class Index: {y_sample_pred_index}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# --- 1. SHAP Implementation ---\n",
        "\n",
        "print(\"Generating SHAP Explanation...\")\n",
        "\n",
        "# SHAP needs a background dataset (subsampled X_train)\n",
        "X_train_df = pd.DataFrame(X_train, columns=data.columns[:-1])\n",
        "\n",
        "# Create a SHAP Explainer using the wrapper function\n",
        "explainer = shap.KernelExplainer(\n",
        "    shap_predict_proba,\n",
        "    X_train_df.iloc[np.random.choice(X_train_df.shape[0], 100, replace=False)]\n",
        ")\n",
        "\n",
        "# Calculate SHAP values\n",
        "X_sample_df = pd.DataFrame(X_sample, columns=data.columns[:-1])\n",
        "shap_values = explainer.shap_values(X_sample_df)\n",
        "\n",
        "print(\"SHAP values calculated successfully.\")\n",
        "print(f\"SHAP values list size: {len(shap_values)}\")\n",
        "\n",
        "\n",
        "# --- FIX SHAP INDEXING ERROR ---\n",
        "# If the explainer returns a list of size 1 (the error you received),\n",
        "# we must assume that single element contains the correct SHAP values and ignore the class index.\n",
        "if len(shap_values) == 1:\n",
        "    # Use the single element in the list, which contains the values for the predicted class\n",
        "    # shap_values[0] is the array of SHAP values for the single sample\n",
        "    predicted_class_shap = shap_values[0][0]\n",
        "else:\n",
        "    # If it's a list of size 41, use the standard indexing\n",
        "    predicted_class_shap = shap_values[y_sample_pred_index][0]\n",
        "\n",
        "# Print the top 5 SHAP values for the predicted class\n",
        "print(f\"Top 5 SHAP features for predicted class: {y_sample_pred_label}\")\n",
        "shap_explanation = list(zip(X_sample_df.columns, predicted_class_shap))\n",
        "shap_explanation.sort(key=lambda x: abs(x[1]), reverse=True)\n",
        "print(shap_explanation[:5])\n",
        "\n",
        "# --- 2. LIME Implementation (Kept successful logic) ---\n",
        "\n",
        "print(\"\\nGenerating LIME Explanation...\")\n",
        "\n",
        "# Create a LIME Explainer\n",
        "explainer_lime = lime_tabular.LimeTabularExplainer(\n",
        "    training_data=X_train,\n",
        "    feature_names=data.columns[:-1].tolist(),\n",
        "    class_names=le_loaded.classes_.tolist(),\n",
        "    mode='classification',\n",
        "    kernel_width=0.75,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Generate LIME explanation for the sample instance (X_sample[0])\n",
        "explanation_lime = explainer_lime.explain_instance(\n",
        "    data_row=X_sample[0],\n",
        "    predict_fn=ensemble_predict_proba,\n",
        "    num_features=5,\n",
        "    top_labels=1\n",
        ")\n",
        "\n",
        "# Access the explanation using the predicted class index\n",
        "print(f\"LIME explanation for predicted class: {y_sample_pred_label}\")\n",
        "print(explanation_lime.as_list(label=y_sample_pred_index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "3d28c3944d9a4684a776ecd94698fe9c",
            "484f45e8ffdc47e6a7a403f09ea6f290",
            "a8a78670eb534735aeeffc2aaaf33912",
            "8d9281e558c1435791c17fc63f1ea0dd",
            "1d391fcb170f4335882c324591eb5c66",
            "610120528f2a4a628631ed4d357e2537",
            "9c11c46b6944417ca1bcbafbc68dad5d",
            "f6cf092fba74487d968002259d7a52bb",
            "f132383a3258474fbaa4505361ed96e6",
            "8518b48215ca4789a22615bc5d4c3d0f",
            "4fb9862371ac4c729849642d52ceb578"
          ]
        },
        "id": "C17xVAw78dXK",
        "outputId": "3f20bd4e-dbfb-4141-deb9-f5b522461444"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Explaining Patient Index 100 ---\n",
            "True Label: No_Disease | Predicted Label: Arthritis\n",
            "Predicted Class Index: 5\n",
            "----------------------------------------\n",
            "Generating SHAP Explanation...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3d28c3944d9a4684a776ecd94698fe9c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SHAP values calculated successfully.\n",
            "SHAP values list size: 1\n",
            "Top 5 SHAP features for predicted class: Arthritis\n",
            "[('Symptom_18', np.float64(0.00449904964688879)), ('Symptom_20', np.float64(-0.0029454833398634564)), ('Symptom_37', np.float64(0.002325935336828263)), ('Symptom_1', np.float64(-0.0021669542773371008)), ('Symptom_7', np.float64(-0.0021506998635250265))]\n",
            "\n",
            "Generating LIME Explanation...\n",
            "LIME explanation for predicted class: Arthritis\n",
            "[('Symptom_3 <= 0.00', 5.858082830970666e-06), ('0.00 < Symptom_8 <= 1.00', 5.652746402195897e-06), ('Symptom_1 <= 0.00', 2.953924574117862e-06), ('0.00 < Symptom_4 <= 1.00', 2.328269858710304e-06), ('0.00 < Symptom_37 <= 1.00', 2.3081918967291226e-06)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the app.py file\n",
        "STREAMLIT_APP_FILE = 'app.py'\n",
        "\n",
        "# Define the Streamlit code as a list of lines.\n",
        "streamlit_lines = [\n",
        "    \"import streamlit as st\",\n",
        "    \"import pandas as pd\",\n",
        "    \"import numpy as np\",\n",
        "    \"import pickle\",\n",
        "    \"import shap\",\n",
        "    \"import lime\",\n",
        "    \"from lime import lime_tabular\",\n",
        "    \"from pytorch_tabnet.tab_model import TabNetClassifier\",\n",
        "    \"import torch\",\n",
        "    \"import warnings\",\n",
        "    \"warnings.filterwarnings('ignore')\",\n",
        "    \"\",\n",
        "    \"# --- 1. CONFIGURATION AND MODEL LOADING ---\",\n",
        "    'st.set_page_config(page_title=\"Medical Diagnosis AI Assistant\", layout=\"wide\")',\n",
        "    \"\",\n",
        "    \"# Constants from training\",\n",
        "    \"N_FEATURES = 50\",\n",
        "    \"# FINAL FIX: Descriptive symptom names defined in one line and correctly formatted.\",\n",
        "    \"FEATURE_NAMES = ['Fever', 'Cough', 'Headache', 'Fatigue', 'Sore_Throat', 'Difficulty_Breathing', 'Chest_Pain', 'Nausea', 'Vomiting', 'Diarrhea', 'Abdominal_Pain', 'Rash', 'Joint_Pain', 'Muscle_Aches', 'Loss_of_Smell', 'Loss_of_Taste', 'Chills', 'Runny_Nose', 'Body_Ache', 'Dizziness', 'Lightheadedness', 'Weakness', 'Loss_of_Appetite', 'Weight_Loss', 'Swollen_Glands', 'Blurred_Vision', 'Ear_Ache', 'Tingling_in_Limbs', 'Numbness', 'Anxiety', 'Depression', 'Insomnia', 'Hives', 'Itching', 'Jaundice', 'Dark_Urine', 'Pale_Stool', 'Tiredness', 'Night_Sweats', 'Constipation', 'Heart_Palpitations', 'Shortness_of_Breath', 'Frequent_Urination', 'Burning_Urination', 'Bloating', 'Back_Pain', 'Neck_Stiffness', 'Confusion', 'Fainting', 'Tremor']\",\n",
        "    \"TABNET_MODEL_LOAD_NAME = 'tabnet_model'\",\n",
        "    \"XGB_MODEL_FILE = 'xgb_model.pkl'\",\n",
        "    \"ENCODER_FILE = 'label_encoder.pkl'\",\n",
        "    \"\",\n",
        "    \"# Helper function to load all assets\",\n",
        "    \"@st.cache_resource\",\n",
        "    \"def load_assets():\",\n",
        "    \"    # Load Label Encoder\",\n",
        "    \"    with open(ENCODER_FILE, 'rb') as f:\",\n",
        "    \"        le_loaded = pickle.load(f)\",\n",
        "    \"\",\n",
        "    \"    # Load XGBoost model\",\n",
        "    \"    with open(XGB_MODEL_FILE, 'rb') as f:\",\n",
        "    \"        xgb_model_loaded = pickle.load(f)\",\n",
        "    \"\",\n",
        "    \"    # Load TabNet model\",\n",
        "    \"    tabnet_model_loaded = TabNetClassifier(n_a=8, n_d=8)\",\n",
        "    \"    try:\",\n",
        "    \"        tabnet_model_loaded.load_model(TABNET_MODEL_LOAD_NAME)\",\n",
        "    \"    except:\",\n",
        "    \"        # Fallback load if the first method fails\",\n",
        "    \"        tabnet_model_loaded.load_model(f'{TABNET_MODEL_LOAD_NAME}.zip')\",\n",
        "    \"        \",\n",
        "    \"    # Dummy X_train data for LIME explainer\",\n",
        "    \"    N_SAMPLES_LIME = 1000\",\n",
        "    \"    X_train_dummy = np.random.randint(0, 2, size=(N_SAMPLES_LIME, N_FEATURES))\",\n",
        "    \"    \",\n",
        "    \"    return le_loaded, xgb_model_loaded, tabnet_model_loaded, X_train_dummy\",\n",
        "    \"\",\n",
        "    \"le, xgb_model, tabnet_model, X_train_for_lime = load_assets()\",\n",
        "    \"\",\n",
        "    \"# --- 2. ENSEMBLE PREDICTION FUNCTIONS ---\",\n",
        "    \"def ensemble_predict_proba(X):\",\n",
        "    '    \"\"\"Generates combined prediction probabilities using soft voting.\"\"\"',\n",
        "    \"    tabnet_proba = tabnet_model.predict_proba(X.astype(np.float32))\",\n",
        "    \"    xgb_proba = xgb_model.predict_proba(X)\",\n",
        "    \"    ensemble_proba = (tabnet_proba + xgb_proba) / 2\",\n",
        "    \"    return ensemble_proba\",\n",
        "    \"\",\n",
        "    \"def ensemble_predict(X):\",\n",
        "    '    \"\"\"Generates the final class prediction based on ensemble probability.\"\"\"',\n",
        "    \"    ensemble_proba = ensemble_predict_proba(X)\",\n",
        "    \"    predictions = np.argmax(ensemble_proba, axis=1)\",\n",
        "    \"    return predictions\",\n",
        "    \"\",\n",
        "    \"\",\n",
        "    \"# --- 3. EXPLAINABILITY FUNCTIONS (LIME) ---\",\n",
        "    \"@st.cache_resource\",\n",
        "    \"def get_lime_explainer():\",\n",
        "    '    \"\"\"Initializes and caches the LIME explainer.\"\"\"',\n",
        "    \"    # Define all 50 features as categorical (indices 0 through 49)\",\n",
        "    \"    categorical_features_indices = list(range(N_FEATURES))\",\n",
        "    \"    # Define human-readable names for the values 0 and 1 (CRITICAL FIX)\",\n",
        "    \"    categorical_names_map = {0: 'No (0)', 1: 'Yes (1)'}\",\n",
        "    \"    \",\n",
        "    \"    explainer_lime = lime_tabular.LimeTabularExplainer(\",\n",
        "    \"        training_data=X_train_for_lime,\",\n",
        "    \"        feature_names=FEATURE_NAMES,\",\n",
        "    \"        class_names=le.classes_.tolist(),\",\n",
        "    \"        mode='classification',\",\n",
        "    \"        kernel_width=0.75,\",\n",
        "    \"        random_state=42,\",\n",
        "    \"        categorical_features=categorical_features_indices,\",\n",
        "    \"        categorical_names=categorical_names_map,\",\n",
        "    \"        discretize_continuous=False\",\n",
        "    \"    )\",\n",
        "    \"    return explainer_lime\",\n",
        "    \"\",\n",
        "    \"lime_explainer = get_lime_explainer()\",\n",
        "    \"\",\n",
        "    \"# --- 4. STREAMLIT UI LAYOUT ---\",\n",
        "    \"\",\n",
        "    'st.title(\"👨‍⚕️ AI-Powered Medical Diagnosis Assistant with Explainable AI\")',\n",
        "    'st.markdown(\"Developed ensemble models (TabNet + XGBoost) for real-time risk assessment.\")',\n",
        "    \"\",\n",
        "    \"# --- SIDEBAR: Input Area ---\",\n",
        "    'st.sidebar.header(\"Patient Symptom Input\")',\n",
        "    \"st.sidebar.markdown(\\\"Select 'Yes' (1) if the symptom is present, 'No' (0) if absent.\\\")\",\n",
        "    \"\",\n",
        "    \"user_input = {}\",\n",
        "    \"# Create a selectbox for each of the 50 symptoms\",\n",
        "    \"for i in range(N_FEATURES):\",\n",
        "    \"    symptom = FEATURE_NAMES[i]\",\n",
        "    \"    # Display name converts Underscore to Space (e.g., Sore_Throat -> Sore Throat)\",\n",
        "    \"    selection = st.sidebar.selectbox(f\\\"**{symptom.replace('_', ' ')}**\\\", options=['No (0)', 'Yes (1)'], index=0, key=f'symptom_{i}')\",\n",
        "    \"    user_input[symptom] = int(selection.split('(')[1].replace(')', ''))\",\n",
        "    \"\",\n",
        "    \"# Convert input to DataFrame for prediction\",\n",
        "    \"input_df = pd.DataFrame([user_input])\",\n",
        "    \"input_array = input_df.values.astype(np.float32)\",\n",
        "    \"\",\n",
        "    \"# --- MAIN PAGE: Results ---\",\n",
        "    'st.header(\"Diagnosis and Explainability Results\")',\n",
        "    \"\",\n",
        "    \"if st.sidebar.button(\\\"Analyze Patient Data\\\", key='analyze_btn'):\",\n",
        "    '    st.subheader(\"1. Real-Time Risk Assessment\")',\n",
        "    \"    \",\n",
        "    \"    # 1. Prediction (Real-Time processing <2 seconds)\",\n",
        "    \"    with st.spinner('Analyzing symptoms and generating ensemble prediction...'):\",\n",
        "    \"        \",\n",
        "    \"        import time\",\n",
        "    \"        start_time = time.time()\",\n",
        "    \"        \",\n",
        "    \"        y_pred_index = ensemble_predict(input_array)[0]\",\n",
        "    \"        y_pred_label = le.inverse_transform([y_pred_index])[0]\",\n",
        "    \"        y_pred_proba_all = ensemble_predict_proba(input_array)[0]\",\n",
        "    \"        \",\n",
        "    \"        y_pred_proba = y_pred_proba_all[y_pred_index]\",\n",
        "    \"        \",\n",
        "    \"        end_time = time.time()\",\n",
        "    \"        processing_time = end_time - start_time\",\n",
        "    \"    \",\n",
        "    \"    # Display Prediction\",\n",
        "    \"    col_pred, col_time = st.columns(2)\",\n",
        "    \"    col_pred.metric(\",\n",
        "    '        label=\"Predicted Diagnosis\", ',\n",
        "    \"        value=y_pred_label, \",\n",
        "    '        delta=f\"Risk: {y_pred_proba:.2%}\",',\n",
        "    '        delta_color=\"off\"',\n",
        "    \"    )\",\n",
        "    \"    col_time.metric(\",\n",
        "    '        label=\"Processing Time\",',\n",
        "    '        value=f\"{processing_time:.3f} seconds\",',\n",
        "    '        delta=\"< 2 seconds (Goal)\",',\n",
        "    '        delta_color=\"inverse\" if processing_time >= 2 else \"normal\"',\n",
        "    \"    )\",\n",
        "    \"\",\n",
        "    '    st.subheader(\"2. Explainable AI (LIME)\")',\n",
        "    '    st.markdown(f\"**Top 5 symptoms influencing the diagnosis of `{y_pred_label}`.**\")',\n",
        "    \"    \",\n",
        "    \"    # 2. Explainability (LIME)\",\n",
        "    \"    with st.spinner('Generating LIME explanation...'):\",\n",
        "    \"        explanation = lime_explainer.explain_instance(\",\n",
        "    \"            data_row=input_array[0],\",\n",
        "    \"            predict_fn=ensemble_predict_proba,\",\n",
        "    \"            num_features=5,\",\n",
        "    \"            top_labels=1\",\n",
        "    \"        )\",\n",
        "    \"        \",\n",
        "    \"        # Get explanation for the predicted class index\",\n",
        "    \"        lime_results = explanation.as_list(label=y_pred_index)\",\n",
        "    \"\",\n",
        "    \"    # Display LIME results in a table\",\n",
        "    \"    lime_df = pd.DataFrame(lime_results, columns=['Symptom', 'Impact Weight'])\",\n",
        "    \"    \",\n",
        "    \"    st.dataframe(lime_df, use_container_width=True)\",\n",
        "    \"    \",\n",
        "    \"    st.markdown(\\\"\\\"\\\"\",\n",
        "    \"        * **Impact Weight > 0**: The symptom pushes the prediction **towards** the predicted diagnosis.\",\n",
        "    \"        * **Impact Weight < 0**: The symptom pushes the prediction **away** from the predicted diagnosis.\",\n",
        "    \"    \\\"\\\"\\\")\",\n",
        "    \"    \",\n",
        "    '    st.subheader(\"3. Patient Similarity Recommendations (Placeholder)\")',\n",
        "    '    st.info(\"This feature would typically query a database (SQLite) for similar patient records and their outcomes. *Implementation deferred for current scope.*\")',\n",
        "    \"\",\n",
        "    \"else:\",\n",
        "    \"    st.info(\\\"👈 Enter patient symptoms in the sidebar and click 'Analyze Patient Data'.\\\")\"\n",
        "]\n",
        "\n",
        "# Join the list of lines with newline characters\n",
        "streamlit_code = \"\\n\".join(streamlit_lines)\n",
        "\n",
        "# Write the Streamlit code to the file\n",
        "with open(STREAMLIT_APP_FILE, 'w') as f:\n",
        "    f.write(streamlit_code)\n",
        "\n",
        "print(f\"Streamlit application code written to {STREAMLIT_APP_FILE}\")\n",
        "print(\"All models, encoder, and the application file are ready for deployment.\")"
      ],
      "metadata": {
        "id": "frl8W8da9wOD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e86885b3-da81-447b-beac-f965decd0c4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit application code written to app.py\n",
            "All models, encoder, and the application file are ready for deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Install pyngrok and upgrade ngrok binary if needed\n",
        "!pip install pyngrok -q\n",
        "!pip install --upgrade ngrok -q\n",
        "\n",
        "# 2. Authenticate ngrok using the shell command (safest method)\n",
        "# *** CRITICAL: REPLACE \"PASTE_YOUR_FULL_TOKEN_HERE\" with your actual, complete ngrok token ***\n",
        "YOUR_FULL_TOKEN = \"cr_343E12HAMa4TitZT8f4I2ukWm83\"\n",
        "!ngrok authtoken $YOUR_FULL_TOKEN\n",
        "\n",
        "print(\"ngrok authentication saved. Now ready for deployment.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5KbVp8vAhch",
        "outputId": "e23acced-eb37-4bed-d46f-055be2fe7232"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "The folder you are executing pip from can no longer be found.\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "The folder you are executing pip from can no longer be found.\n",
            "shell-init: error retrieving current directory: getcwd: cannot access parent directories: No such file or directory\n",
            "panic: getwd: no such file or directory\n",
            "\n",
            "goroutine 1 [running]:\n",
            "github.com/go-martini/martini.init.0()\n",
            "\tgithub.com/go-martini/martini@v0.0.0-20170121215854-22fa46961aab/env.go:29 +0x9a\n",
            "ngrok authentication saved. Now ready for deployment.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37PgEK-0YGzk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}